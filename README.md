# SC1015
SC1015 Data Science &amp; Artificial Intelligence project
#Twitter Hate Speech Detector

## Overview

In today's digital age, social media platforms like Twitter have become breeding grounds for hate speech and cyberbullying. This project aims to address this issue by developing a hate speech detector specifically tailored for Twitter. By leveraging machine learning techniques, we aim to automatically identify and flag tweets containing hateful or abusive language. Five different models - Random Forest, Nearest Neighbour, Decision Tree, Logistic Regression, and Naive Bayes - will be explored and compared to determine the most effective approach for hate speech detection on Twitter.

## When to Use Hate Speech Detection?
Hate speech detection can be employed in various scenarios including:
#### Moderating social media platforms to remove hateful content.
#### Identifying and addressing online harassment and cyberbullying.
#### Monitoring online communities to ensure a safe environment for users.
#### Analyzing trends in hate speech for research and policy-making purposes.


## Dataset

The dataset used for this project is a curated collection of data from various social media platforms including Twitter, Kaggle, Wikipedia Talk pages, and YouTube. Each instance in the dataset consists of a tweet along with corresponding annotations indicating whether it contains hate speech or not. The data encompasses different types of cyberbullying such as hate speech, aggression, insults, and toxicity. To ensure robustness and generalization, the dataset is divided into training and testing sets for model training and evaluation.


## Models used:

### Random Forest:
### Nearest Neighbour:
### Decision Tree:
### Logistic Regression:
### Naive Bayes:

## Results and Conclusion
The evaluation results will be presented, showcasing the performance metrics of each model and comparing their effectiveness in hate speech detection. Additionally, insights gained from the analysis will be discussed, highlighting the strengths and weaknesses of each model.
Based on the evaluation results, the most effective model for hate speech detection on Twitter will be identified. Recommendations for further improvements, model optimization, and deployment of the hate speech detector will also be discussed, aiming to contribute to the ongoing efforts in combating online hate speech and fostering a safer online environment

## What did we learn from this?


## Contributions:
John Doe: Model evaluation and conclusion.
Jane Smith: Data preprocessing and model selection.

## References:
Insert references here.
